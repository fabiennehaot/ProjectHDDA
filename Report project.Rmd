---
title: "HDDA Project"
<<<<<<< HEAD
author: "L. Barbier, K. De Witte, F. Haot, K. Putseys"
date: "12/16/2021"
bibliography: references.bib
=======
author: "Lisa Barbier, Klara Dewitte, Fabienne Haot, Kasimir Putseys"
date: "December 2021"
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gridExtra)
library(HDDAData)
library(glmnet)
library(MASS)
library(locfdr)
library(boot)
library(pROC)
```

# Research Question

# Executive Summary

# Technical Report

## Data

Data description in [@einecke:2010]
```{r getdata}
data("Einecke2010Kidney")
X_raw <- Einecke2010Kidney[, -1]
<<<<<<< HEAD
Y <- factor(Einecke2010Kidney[, 1], 
            levels = c(0,1),labels = c('accept','reject'))
=======
Y <- factor(Einecke2010Kidney[, 1], levels = c(0, 1),labels = c('accept', 'reject'))
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
```

## Exploration of the Data

## Hypothesis Testing 


Not every gene in the data set is an indicator for kidney rejection. In this section we find out which genes are differentially expressed between the two kidney rejection groups. Since we do not know a priori whether differentiated genes will show higher or lower intensities we opt for 2 sided t-tests with unequal variances. 

\[H_0: \mu_{normal}(gene) = \mu_{reject}(gene) \]
\[H_1: \mu_{normal}(gene) \neq \mu_{reject}(gene) \]

We first perform these t-tests for every gene in the data, with an individual significance level of 5%. Because we are performing multiple testing we would expect to find about 500 genes with a p-value lower than 5% if the null hypothesis holds for all the genes. 

```{r hyptest_unadjusted, fig.height= 4}
gene_data <- as.matrix(X_raw)
group <- Y
# non adjusted p-values as named vector
significance_level <- 0.05
ttest_results <- apply(gene_data, 2, function(x) {
  t_test <- t.test(x ~ group)
  p_val <- t_test$p.value
  stat <- t_test$statistic
  df <- t_test$parameter
  z_val <- case_when(stat < 0 ~ qnorm(p_val/2), TRUE~ qnorm(1-p_val/2))
  tibble(stat = stat, p_val = p_val,z_val = z_val, df = df)})
t_stats <- bind_rows(ttest_results) %>%
<<<<<<< HEAD
  mutate(gene = colnames(X_raw),
         isdetected_t = factor(p_val < significance_level,
                         levels=c(TRUE, FALSE),
                         labels = c('detected','H0 not rejected')))

# plot histogram for the unadjusted z-values
mean_z <- round(mean(t_stats$z_val),3) 
sd_z <- round(sd(t_stats$z_val),3) 

ggplot(data=t_stats) + 
  geom_histogram(mapping=aes(x = z_val,fill=isdetected_t),bins=20,alpha = .7)+
  scale_fill_manual(values=c("firebrick","lightblue")) +
  labs(title = "multiple t-tests",
       subtitle="histogram of transformed z-values",
       x = "z-values")+
  annotate(geom="text", x=-8, y=1500, 
           label=paste0("mean: ", mean_z,"\nstdev:", sd_z))+
=======
  mutate(
    gene = colnames(X_raw),
    relevant = cut(z_val,
                   c(-Inf, qnorm(.025), qnorm(.975), Inf), 
                   labels = c('low', 'mid', 'high')))


ggplot(data=as.data.frame(t_stats)) + 
  geom_point(mapping = aes(x = seq_along(stat), y = stat,
                         color = relevant),size=.3)+
  labs(title = "t-statistics", x = "gene", y = "unadjusted t-statistic",
       caption = "There are more observations in the lower tail") +
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
  theme_bw()

# number and names of differentiated genes
table_p_nonadj <- table(t_stats$p_val < 0.05)
<<<<<<< HEAD
nonadj_diff_genes <- t_stats %>% filter(p_val<.05) %>% .$gene
=======
no_corr_genes <- t_stats %>% 
  filter(p_val < .05) %>%
  .$gene
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
```

There are `r as.numeric(table_p_nonadj['TRUE'])` out of 10000 genes with unadjusted p-value below 0.05, while we expected to find 500 genes if the null hypothesis were true for all the genes.  

The histogram does not show a standard normal distribution as the observations are skewed to the left. We can derive from this histogram that the differentiated genes tend to have higher intensities in the group with rejected kidneys. There is also reason to assume that the non-differentiated genes give rise to a null distribution which is not standard normal.


```{r hyptest_fdr_hist}
#fdr analysis - current behaviour of p-values: uniform?
t_stats %>%
  ggplot(aes(x = p_val)) +
<<<<<<< HEAD
  geom_histogram(fill = "firebrick",breaks = seq(0,1,.05),alpha=.7)+
=======
  geom_histogram(fill = "firebrick",breaks = seq(0, 1, .05))+
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
  labs(title = 'histogram of p-values')+
  theme_bw()
```

This histogram should show a distribution which is close to a uniform distribution
for the larger p-values, but with higher frequencies for the smallest p-values.
The higher number of genes with small p-values indicate in that situation that some genes show a different behaviour regarding kidney rejection. 

We see a more of less constant frequency for p-values higher than 35%, we also see a clear peak for p-values lower than 5% but the frequencies for values between 5% and 35% are not constant. The assumption of a standard normal null distribution is not valid. Because of this we underestimate the lower tail of the non differentiated genes with respect to the rejection status. We will scale the z values to a standard normal distribution and recalculate the associated p-values. 

We will also adjust for multiple testing by controlling the false detection ratio (FDR = 10%): the list with detected genes will contain false positives, but the ratio of the truly differentiated detected genes and all the detected genes is expected to be 90%. The p-values are adjusted using the Benjamini and Hochberg[@BH:1995] procedure. 

```{r hyptest_fdr_padj}
# adjusted p values
fdr_level <- 0.1
t_stats <- t_stats %>%
<<<<<<< HEAD
  mutate(z_scale = (z_val - mean(z_val))/sd(z_val),
         p_scale = pnorm(z_scale),
         p_adj = p.adjust(p_scale, method="fdr"),
         isdetected_fdr = factor(p_adj< fdr_level,
                         levels=c(TRUE,FALSE),
                         labels = c('detected','H0 not rejected')))

# monotonous transformation:
pp_adj <- t_stats %>%
  ggplot(aes(x=p_scale,y=p_adj)) +
  geom_point(size = .3,color='red') +
  geom_segment(x=0,y=0,xend=1,yend=1) +
  labs(y= "adjusted p-value (BH, 1995)") +
  theme_bw()

# right plot removes observations with high fdr 
suppressWarnings(
  grid.arrange(pp_adj,
             pp_adj + ylim(c(0,fdr_level)),
             ncol=2))
=======
  mutate(p_adj = p.adjust(p_val, method = "fdr"))

# monotonous transformation:
pp_adj <- t_stats %>%
  ggplot(aes(x = p_val, y = p_adj)) +
  geom_point(size = .3, color = 'blue') +
  geom_segment(x = 0, y = 0, xend = 1, yend = 1) +
  labs(y = "adjusted p-value (BH, 1995)") +
  theme_bw()

# right plot removes observations with high fdr 
# 8090 obs are removed when ylim .05
# 7575 when ylim .1
# plotting seems to take a while
grid.arrange(pp_adj,
             pp_adj + ylim(c(0, fdr_level)),
             ncol = 2)
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1

# these are the detected genes and a histogram of their t-values
table_p_adj <- table(t_stats$p_adj < fdr_level)
nr_detected_fdr <- as.numeric(table_p_adj['TRUE'])
fdr_genes <- t_stats %>% filter(p_adj < fdr_level)%>% .$gene
ggplot(t_stats) + 
  scale_fill_manual(values=c("firebrick","lightblue")) +
  geom_histogram(mapping=aes(x = stat, fill=isdetected_fdr), bins = 20,alpha=.7)+
  labs(title= 't-statistics for differentiated genes FDR',
       subtitle = ' p-values, rescaled and adjusted for multiple testing')+
  theme_bw()            
  
```

The scaling has lowerd the number of candidate genes drastically.
There are now `r nr_detected_fdr` out of 10000 genes with adjusted p-value below 10%. We still expect `r round(nr_detected_fdr/10,-1)` of these genes to be false detections. 

All of the detected genes are found in the lower tail, which seems acceptable. The histogram of the non selected genes is still skewed to the left however. The histogram also gives the impression that we should have gotten more differenciated genes.

We will try to make a better list using a local approach where we assume that the observed histogram represents a mixture of different Gaussian distributions, each with their own mean and standard deviance. We will use the z-values before scaling for this part. The means and standard deviance of the different distributions will be calculated using maximum likelihood.



```{r localfdr}
#local fdr
fdr_x <- locfdr(t_stats$z_val,plot=4) 
prop_h0 <- fdr_x$fp0['mlest','p0']
```

The left plot shows the density of both population. The proportion of differentiated genes is expected to be`r round(100*(1 - prop_h0),2)` percent. This means `r round(10000*(1 - prop_h0),0)`genes for our data set. The blue line represents the null distribution, the purple bars represent the differentiated genes. We do not expect to find signal genes with high t-values. 

The second plot shows the local false discovery rate. Since we want to control the FDR we are more interested in the red dashed line, which represents the left FDR-graph with the FDR for all the genes in the left tail of the empirical distribution. The Efdr represents the expected local fdr for a typical non-null feature, i.e. the mean local fdr, weighted with the density represented by all the purple bars.

<<<<<<< HEAD

```{r control_lfdr}

FDR_left <- fdr_x$mat[,'Fdrleft']
z_mat <- fdr_x$mat[,'x']
lfdr_mat <- fdr_x$mat[,'fdr']
dens1_mat <- fdr_x$mat[,'p1f1'] 

id <- which.max(FDR_left[FDR_left < fdr_level])
t_int <- (fdr_level - FDR_left[id])/(FDR_left[id+1] - FDR_left[id])
threshold <- z_mat[id] * (1-t_int) + z_mat[id]*t_int 
lfdr_level <- lfdr_mat[id] * (1-t_int) + lfdr_mat[id]*t_int
cdf_true_positive = sum(dens1_mat[1:id])+ dens1_mat[id+1]* t_int
prop_tp_r <- cdf_true_positive/sum(dens1_mat)
=======
fdr_x <- locfdr(t_stats$z_val, plot = 3) 
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
```

The threshold for a local fdr of 20% is `r fdr_x$z.2[1]`. If we want to control the FDR for 10%, we have to find the value on the x-axis for which the left FDR - graph is equal to 10%. The threshold for the z-values using interpolation on the points of the left FDR-graph becomes: `r round(threshold,3)`.

The third graph returns the probability that a non-null gene can be detected when the nominal local fdr is set at a given local fdr-level. The local fdr-level associated with an FDR of 10% is `round(100* lfdr_level,1)` percent which means that we expect `r round(100*prop_tp_r)` percent of all differentiated genes to be correctly identified.   

```{r lfdr_genes}

t_stats <- t_stats %>%
  mutate(
    lfdr = fdr_x$fdr,
    zfdr = (lfdr < lfdr_level) * z_val,
    isdetected_lfdr = factor(lfdr < lfdr_level,
                        levels= c(TRUE,FALSE),
                        labels = c('detected','H0 not rejected')))
summ_lfdr <- t_stats %>%
  filter(lfdr < lfdr_level) %>%
<<<<<<< HEAD
  summarize(nr_of_genes=n(), mean_lfdr=mean(lfdr))

ggplot(t_stats) + 
  scale_fill_manual(values=c("firebrick","lightblue")) +
  geom_histogram(mapping=aes(x = stat, fill=isdetected_lfdr), bins = 20,alpha = .7)+
  labs(title= 't-statistics for differentiated genes Local FDR')+
  theme_bw()       
lfdr_genes <- t_stats %>% filter(lfdr < lfdr_level)%>% .$gene
=======
  summarize(nr_of_genes = n(), mean_fdr = mean(lfdr))
>>>>>>> a62b877bd2ca1b45d534b311c9c01ab4f3ba8da1
```

We have found `r summ_lfdr$nr_of_genes` candidates for differentiated genes. The mean local fdr the detected genes is `r round(100*summ_lfdr$mean_lfdr,1)` percent, which means we expect to have `r round(summ_lfdr$mean_lfdr* summ_lfdr$nr_of_genes)` falsely detected genes. The genes detected by the of the local fdr will be added as an appendix.  

## Model Selection
In the next step we want the predict the rejection status using the gene expression levels. Therefore, we first start with splitting the dataset into a train (70%) and test (30%) dataset.

Hier ook nog de testset deftig scalen? maar hoe?

```{r training and test data}
set.seed(1234)
trainset <- sample(nrow(X_raw), 0.7*nrow(X_raw))
trainX <- X_raw[trainset, ]
trainX <- scale(trainX, center = TRUE, scale = TRUE)
dim(trainX) #175*10000
trainY <- Y[trainset]

testX <- X_raw[-trainset, ]
dim(testX) #75*10000
testY <- Y[-trainset]

train_data <- data.frame(trainY, trainX)
test_data <- data.frame(testY, testX)
```
Here, we will evaluate three prediction models: principal component regression (PCR), Ridge regression and Lasso regression.

# Principal compentent regression (PCR)

```{r PCR}
# Calculate PCA and extract scores
pca_X <- prcomp(trainX)
Z <- pca_X$x

## Total number of available PCs
n_PC <- ncol(Z)
n_PC
```
First, the principal components are calculated and the total number of available PC's is selected. In our case, `r n_PC` PC's are available.

```{r full PCR, cache=TRUE}
fit_data <- data.frame(trainY, Z)

## Example of PC Log. Reg. with all PCs
full_model <- suppressMessages(glm(trainY ~ ., data = fit_data, family = "binomial"))

set.seed(1234)
full_model_cv <- suppressMessages(cv.glm(
  data = fit_data,  glmfit = full_model,
  cost = auc, K = 10  # note: specify the auc function (from pROC) without`()`!
))

## We'll just use the raw one here
full_model_cv$delta[1] # This is the AUC for this particular model estimated by AUC
```
First we try to fit a model with all the PCs, using crossvalidation. Via crossvalidation will the training set be divived into (hoeveel we er kiezen) approximately equal subsets. This means we will have overfitting, as the model will predict the training dataset exactly, but this will not be reproducible to other (or the test) dataset. Here we get an area under the curve (AUC) of `r full_model_cv$delta[1]`.

```{r each PC, cache=TRUE}
## Now we'll wrap this code in a for-loop and repeat for each number of PCs
cv_auc <- vector("numeric", length = n_PC)
set.seed(1234) # seed for reproducibility
for (i in seq_len(n_PC)) {
  ## Prepare fit_data; subset number of PCs to i
  fit_data <- data.frame(trainY, Z[, 1:i, drop = FALSE])  # use drop = FALSE to avoid problems when subsetting single column
  pcr_mod <- suppressMessages(
    glm(trainY ~ ., data = fit_data, family = "binomial")
  )
  
  ## Do 4-fold CV while suppressing Warnings and Messages
  cv <- suppressMessages(
      cv.glm(fit_data, pcr_mod, cost = pROC::auc, K = 4)
            )
  cv_auc[i] <- cv$delta[1]
}

#als ik hier een k=10 gebruik, krijg ik de Error in roc.default(response, predictor, auc = TRUE, ...) : 'response' must have two levels
names(cv_auc) <- seq_along(cv_auc) => niet in alle CV trainingsets zit dan de 2 rejection status?
cv_auc

## Finding the optimal nr. of PCs corresponds to finding the max. AUC
optim_nPC <- names(which.max(cv_auc))
optim_nPC
cv_auc[optim_nPC]

plot(names(cv_auc), cv_auc, xlab = "n PCs", ylab = "AUC", type = "l")
abline(v = optim_nPC, col = "red")
```

In a second step, we loop and repeat this for each PC. This gives us the optimal number of PC's of `r optim_nPC`, which corresponds to an AUC of `cv_auc[optim_nPC]`.

```{r PCR, cache=TRUE}
pca <- prcomp(trainX)
Vk <- pca$rotation[, 1:optim_nPC] # the loadings matrix
Zk <- pca$x[, 1:l]

pcr_model1 <- glm(trainY ~ Zk, family = "binomial")
summary(pcr_model1)
suppressMessages(plot(pcr_model1, plottype = "validation"))
```
In the last step, a principle component egression model with `r optim_nPC` is fitted. 

# Ridge regression

# Lasso regression

## Model Evaluation

## Conclusions


## References
<div id="refs"></div>

## Appendix: Names of candidate differentiated genes
`r lfdr_genes`
